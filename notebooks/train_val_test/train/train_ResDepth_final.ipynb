{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a54d384-100e-4f91-b8b0-44ce430c3e8e",
   "metadata": {},
   "source": [
    "# Train a model on the deep-snow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a93e0af5-5251-47ba-853b-6d43867dca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import deep_snow.models\n",
    "import deep_snow.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa768b49-c7ea-4b12-84bb-5f4628113110",
   "metadata": {},
   "source": [
    "## Prepare dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981de39d-c6cb-4f85-9f11-26ad0785d9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get paths to data\n",
    "train_data_dir = '/mnt/Backups/gbrench/repos/deep-snow/data/subsets_v4/train'\n",
    "train_path_list = glob(f'{train_data_dir}/ASO_50M_SD*.nc')\n",
    "\n",
    "val_data_dir = '/mnt/Backups/gbrench/repos/deep-snow/data/subsets_v4/val'\n",
    "val_path_list = glob(f'{val_data_dir}/ASO_50M_SD*.nc')\n",
    "\n",
    "#consolidate for final run\n",
    "train_path_list = train_path_list + val_path_list\n",
    "\n",
    "test_data_dir = '/mnt/Backups/gbrench/repos/deep-snow/data/subsets_v4/test'\n",
    "test_path_list = glob(f'{test_data_dir}/ASO_50M_SD*.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52738d11-e34f-4af7-8088-c1775076997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to test code with a small sample of the data\n",
    "# import random\n",
    "# n_imgs = 16\n",
    "\n",
    "# train_path_list = random.sample(train_path_list, n_imgs )\n",
    "# val_path_list = random.sample(val_path_list, n_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbe8cd93-40cd-49ce-8d18-060bd4c8aa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data to be returned by dataloader\n",
    "selected_channels = [\n",
    "    # ASO products\n",
    "    'aso_sd', # ASO lidar snow depth (target dataset)\n",
    "    'aso_gap_map', # gaps in ASO data\n",
    "    \n",
    "    # Sentinel-1 products\n",
    "    'snowon_vv', # snow on Sentinel-1 VV polarization backscatter in dB, closest acquisition to ASO acquisition\n",
    "    'snowon_vh', # snow on Sentinel-1 VH polarization backscatter in dB, closest acquisition to ASO acquisition\n",
    "    'snowoff_vv', # snow off Sentinel-1 VV polarization backscatter in dB, closest acquisition to ASO acquisition\n",
    "    'snowoff_vh', # snow off Sentinel-1 VH polarization backscatter in dB, closest acquisition to ASO acquisition\n",
    "    'snowon_vv_mean', # snow on Sentinel-1 VV polarization backscatter in dB, mean of acquisition in 4 week period around ASO acquisition\n",
    "    'snowon_vh_mean', # snow on Sentinel-1 VH polarization backscatter in dB, mean of acquisition in 4 week period around ASO acquisition\n",
    "    'snowoff_vv_mean', # snow off Sentinel-1 VV polarization backscatter in dB, mean of acquisition in 4 week period around ASO acquisition\n",
    "    'snowoff_vh_mean', # snow off Sentinel-1 VH polarization backscatter in dB, mean of acquisition in 4 week period around ASO acquisition\n",
    "    'snowon_cr', # cross ratio, snowon_vh - snowon_vv\n",
    "    'snowoff_cr', # cross ratio, snowoff_vh - snowoff_vv\n",
    "    'delta_cr', # change in cross ratio, snowon_cr - snowoff_cr\n",
    "    'rtc_gap_map', # gaps in Sentinel-1 data\n",
    "    'rtc_mean_gap_map', # gaps in Sentinel-1 mean data\n",
    "    \n",
    "    # Sentinel-2 products \n",
    "    'aerosol_optical_thickness', # snow on Sentinel-2 aerosol optical thickness band \n",
    "    'coastal_aerosol', # snow on Sentinel-2 coastal aerosol band\n",
    "    'blue', # snow on Sentinel-2 blue band\n",
    "    'green', # snow on Sentinel-2 green band\n",
    "    'red', # snow on Sentinel-2 red band\n",
    "    'red_edge1', # snow on Sentinel-2 red edge 1 band\n",
    "    'red_edge2', # snow on Sentinel-2 red edge 2 band\n",
    "    'red_edge3', # snow on Sentinel-2 red edge 3 band\n",
    "    'nir', # snow on Sentinel-2 near infrared band\n",
    "    'water_vapor', # snow on Sentinel-2 water vapor\n",
    "    'swir1', # snow on Sentinel-2 shortwave infrared band 1\n",
    "    'swir2', # snow on Sentinel-2 shortwave infrared band 2\n",
    "    'scene_class_map', # snow on Sentinel-2 scene classification product\n",
    "    'water_vapor_product', # snow on Sentinel-2 water vapor product\n",
    "    'ndvi', # Normalized Difference Vegetation Index from Sentinel-2\n",
    "    'ndsi', # Normalized Difference Snow Index from Sentinel-2\n",
    "    'ndwi', # Normalized Difference Water Index from Sentinel-2\n",
    "    's2_gap_map', # gaps in Sentinel-2 data\n",
    "\n",
    "    # snodas datset\n",
    "    'snodas_sd', # snow depth\n",
    "\n",
    "    # PROBA-V global land cover dataset (Buchhorn et al., 2020)\n",
    "    'fcf', # fractional forest cover\n",
    "    \n",
    "    # COP30 digital elevation model      \n",
    "    'elevation',\n",
    "    'slope',\n",
    "    'aspect',\n",
    "    'curvature',\n",
    "    'tpi',\n",
    "    'tri',\n",
    "\n",
    "    # latitude and longitude\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "\n",
    "    # day of water year\n",
    "    'dowy'\n",
    "                    ]\n",
    "\n",
    "# prepare training and validation dataloaders\n",
    "train_data = deep_snow.dataset.Dataset(train_path_list, selected_channels, augment=False, norm=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=16, shuffle=True, num_workers=16)\n",
    "val_data = deep_snow.dataset.Dataset(val_path_list, selected_channels, norm=True, augment=False)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_data, batch_size=16, shuffle=True, num_workers=16)\n",
    "# test_data = deep_snow.dataset.Dataset(test_path_list, selected_channels, norm=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=16, shuffle=True, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db0c867b-36a4-4719-9320-3aa19b0766bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input channels for model\n",
    "input_channels = [\n",
    "    'snowon_vv',\n",
    "    'delta_cr',\n",
    "    'green',\n",
    "    'swir2',\n",
    "    'ndsi',\n",
    "    'ndwi',\n",
    "    'snodas_sd',\n",
    "    'elevation',\n",
    "    'latitude',\n",
    "    'longitude']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b36322-9ac5-4a3f-aefa-98ad371d1ee0",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2aebf81-be4e-4200-ab12-70168b8eb37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model\n",
    "# model = deep_snow.models.SimpleCNN(n_input_channels=len(input_channels))\n",
    "# model = deep_snow.models.UNet(n_input_channels=len(input_channels))\n",
    "# model = deep_snow.models.ResUNet(n_input_channels=len(input_channels))\n",
    "# model = deep_snow.models.ResDepth(n_input_channels=len(input_channels))\n",
    "# model = deep_snow.models.VisionTransformer(n_input_channels=len(input_channels))\n",
    "\n",
    "model = deep_snow.models.ResDepth(n_input_channels=len(input_channels), depth=5)\n",
    "model.to('cuda');  # Run on GPU\n",
    "\n",
    "# #load previous model\n",
    "# model = deep_snow.models.ResDepth(n_input_channels=len(input_channels), depth=5)\n",
    "# model.load_state_dict(torch.load('../../weights/quinn_ResDepth_v10_256epochs'))\n",
    "# model.to('cuda');\n",
    "\n",
    "# name your model\n",
    "model_name = 'quinn_ResDepth_v11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5da4e4b7-5679-4e71-b1c3-664346b40060",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300: 100%|██████████████████████████████| 774/774 [42:54<00:00,  3.33s/batch, batch loss=0.00144, mean epoch loss=0.00238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0023772839446418535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300: 100%|█████████████████████████████| 135/135 [06:49<00:00,  3.03s/batch, batch loss=0.000894, mean epoch loss=0.00155]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory ../../weights does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 78\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(val_epoch_loss) \u001b[38;5;241m<\u001b[39m min_val_loss:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m#if epoch > 30:\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     min_val_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(val_epoch_loss)\n\u001b[0;32m---> 78\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../weights/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# if epoch == 200:\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m#     # fine-tune with no augmentation\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m#     train_data = deep_snow.dataset.Dataset(train_path_list, selected_channels, augment=False, norm=True)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# if epoch > 20:\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m#     past_loss = np.mean(test_loss[-20:-10])\u001b[39;00m\n\u001b[1;32m     89\u001b[0m val_loss\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(val_epoch_loss))\n",
      "File \u001b[0;32m/mnt/Backups/gbrench/sw/miniconda3/envs/deep-snow/lib/python3.11/site-packages/torch/serialization.py:849\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    846\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    848\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 849\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    850\u001b[0m         _save(\n\u001b[1;32m    851\u001b[0m             obj,\n\u001b[1;32m    852\u001b[0m             opened_zipfile,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    855\u001b[0m             _disable_byteorder_record,\n\u001b[1;32m    856\u001b[0m         )\n\u001b[1;32m    857\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/Backups/gbrench/sw/miniconda3/envs/deep-snow/lib/python3.11/site-packages/torch/serialization.py:716\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    715\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 716\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/Backups/gbrench/sw/miniconda3/envs/deep-snow/lib/python3.11/site-packages/torch/serialization.py:687\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream))\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 687\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parent directory ../../weights does not exist."
     ]
    }
   ],
   "source": [
    "# Define optimizer and loss function\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0003, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "loss_fn = nn.MSELoss()\n",
    "epochs = 300\n",
    "min_test_loss = 1\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "# training and testidation loop\n",
    "for epoch in range(epochs):\n",
    "    print(f'\\nStarting epoch {epoch+1}')\n",
    "    train_epoch_loss = []\n",
    "    test_epoch_loss = []\n",
    "\n",
    "    # Loop through training data with tqdm progress bar\n",
    "    train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", unit=\"batch\", ncols=130)\n",
    "    for data_tuple in train_pbar:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # read data into dictionary\n",
    "        data_dict = {name: tensor for name, tensor in zip(selected_channels, data_tuple)}\n",
    "        \n",
    "        # prepare inputs by concatenating along channel dimension\n",
    "        inputs = torch.cat([data_dict[channel] for channel in input_channels], dim=1).to('cuda')\n",
    "\n",
    "        # generate prediction\n",
    "        pred_sd = model(inputs)\n",
    "\n",
    "        # Limit prediction to areas with valid data\n",
    "        pred_sd = torch.where(data_dict['aso_gap_map'].to('cuda') + data_dict['rtc_gap_map'].to('cuda') + data_dict['s2_gap_map'].to('cuda') == 0, pred_sd, torch.zeros_like(pred_sd).to('cuda'))\n",
    "        aso_sd = torch.where(data_dict['aso_gap_map'].to('cuda') + data_dict['rtc_gap_map'].to('cuda') + data_dict['s2_gap_map'].to('cuda')== 0, data_dict['aso_sd'].to('cuda'), torch.zeros_like(pred_sd).to('cuda'))\n",
    "\n",
    "        # Calculate loss\n",
    "        train_batch_loss = loss_fn(pred_sd, aso_sd.to('cuda'))\n",
    "        train_epoch_loss.append(train_batch_loss.item())\n",
    "\n",
    "        # Update tqdm progress bar with batch loss\n",
    "        train_pbar.set_postfix({'batch loss': train_batch_loss.item(), 'mean epoch loss': np.mean(train_epoch_loss)})\n",
    "\n",
    "        train_batch_loss.backward()  # Propagate the gradients in backward pass\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss.append(np.mean(train_epoch_loss))\n",
    "    print(f'Training loss: {np.mean(train_epoch_loss)}')\n",
    "    scheduler.step(np.mean(train_epoch_loss))\n",
    "\n",
    "    # Run model on validation data with tqdm progress bar\n",
    "    test_pbar = tqdm(test_loader, desc=f\"Epoch {epoch+1}/{epochs}\", unit=\"batch\", ncols=130)\n",
    "    for data_tuple in test_pbar:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            \n",
    "            # read data into dictionary\n",
    "            data_dict = {name: tensor for name, tensor in zip(selected_channels, data_tuple)}\n",
    "            # prepare inputs by concatenating along channel dimension\n",
    "            inputs = torch.cat([data_dict[channel] for channel in input_channels], dim=1).to('cuda')\n",
    "    \n",
    "            # generate prediction\n",
    "            pred_sd = model(inputs)\n",
    "    \n",
    "            # Limit prediction to areas with valid data\n",
    "            pred_sd = torch.where(data_dict['aso_gap_map'].to('cuda') + data_dict['rtc_gap_map'].to('cuda') + data_dict['s2_gap_map'].to('cuda') == 0, pred_sd, torch.zeros_like(pred_sd).to('cuda'))\n",
    "            aso_sd = torch.where(data_dict['aso_gap_map'].to('cuda') + data_dict['rtc_gap_map'].to('cuda') + data_dict['s2_gap_map'].to('cuda') == 0, data_dict['aso_sd'].to('cuda'), torch.zeros_like(pred_sd).to('cuda'))\n",
    "    \n",
    "            # Calculate loss\n",
    "            test_batch_loss = loss_fn(pred_sd, aso_sd.to('cuda'))\n",
    "            test_epoch_loss.append(test_batch_loss.item())\n",
    "\n",
    "            # Update tqdm progress bar with batch loss\n",
    "            test_pbar.set_postfix({'batch loss': test_batch_loss.item(), 'mean epoch loss': np.mean(test_epoch_loss)})\n",
    "\n",
    "    if np.mean(test_epoch_loss) < min_test_loss:\n",
    "        #if epoch > 30:\n",
    "        min_test_loss = np.mean(test_epoch_loss)\n",
    "        torch.save(model.state_dict(), f'../../weights/{model_name}_{epoch+1+256}epochs')\n",
    "\n",
    "    # if epoch == 200:\n",
    "    #     # fine-tune with no augmentation\n",
    "    #     train_data = deep_snow.dataset.Dataset(train_path_list, selected_channels, augment=False, norm=True)\n",
    "    #     train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=16, shuffle=True, num_workers=16)\n",
    "                            \n",
    "    # # calculate loss over previous 10 epochs for early stopping later\n",
    "    # if epoch > 20:\n",
    "    #     past_loss = np.mean(test_loss[-20:-10])\n",
    "\n",
    "    test_loss.append(np.mean(test_epoch_loss))\n",
    "    print(f'test loss: {np.mean(test_epoch_loss)}')\n",
    "    \n",
    "    # save loss \n",
    "    with open(f'../../loss/{model_name}_test_loss.pkl', 'wb') as f:\n",
    "        pickle.dump(test_loss, f)\n",
    "        \n",
    "    with open(f'../../loss/{model_name}_train_loss.pkl', 'wb') as f:\n",
    "        pickle.dump(train_loss, f)\n",
    "\n",
    "    # # implement early stopping\n",
    "    # if epoch > 20:\n",
    "    #     current_loss = np.mean(test_loss[-10:-1])\n",
    "    #     if current_loss > past_loss:\n",
    "    #         counter +=1\n",
    "    #         if counter >= 10:\n",
    "    #             print('early stopping triggered')\n",
    "    #             # save model\n",
    "    #             torch.save(model.state_dict(), f'../../weights/{model_name}_{epoch}epochs')\n",
    "    #             break\n",
    "    #     else:\n",
    "    #         counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d78371-b064-4e72-9a68-94b91ab43b6a",
   "metadata": {},
   "source": [
    "## Examine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1ab005-2d29-4ff3-b58f-2253a8340512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load previous model\n",
    "# model = deep_snow.models.ResDepth(n_input_channels=len(input_channels), depth=5)\n",
    "# model.load_state_dict(torch.load('../../weights/quinn_ResDepth_v4_74epochs'))\n",
    "# model.to('cuda');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bcd955-2ccd-4194-8af4-90d1309f88aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../../loss/quinn_ResDepth_v11_test_loss.pkl', 'rb') as f:\n",
    "        test_loss = pickle.load(f)\n",
    "\n",
    "with open(f'../../loss/quinn_ResDepth_v11_train_loss.pkl', 'rb') as f:\n",
    "        train_loss = pickle.load(f)\n",
    "\n",
    "\n",
    "# plot loss over all epochs\n",
    "f, ax = plt.subplots(figsize=(10,5))\n",
    "ax.plot(train_loss, label='training')\n",
    "ax.plot(test_loss, label='testing')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('MSE loss')\n",
    "ax.set_title('Loss')\n",
    "ax.legend()\n",
    "\n",
    "# save figure\n",
    "plt.savefig(f'../../figs/quinn_ResDepth_v11_finetune_loss.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7270d680-a813-497b-a06c-6b9d63c7eb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(dataset=val_data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2842a0-6ed9-4dda-bc59-2fd6cda18c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize model predictions\n",
    "sns.set_theme()\n",
    "num_samples = 1\n",
    "\n",
    "for i, data_tuple in enumerate(val_loader):\n",
    "    if i < num_samples:\n",
    "        # read data into dictionary\n",
    "        data_dict = {name: tensor for name, tensor in zip(selected_channels, data_tuple)}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Concatenate input feature channels, make prediction\n",
    "            inputs = torch.cat([data_dict[channel] for channel in input_channels], dim=1).to('cuda')\n",
    "            pred_sd = model(inputs)  # Generate predictions using the model\n",
    "            pred_sd = pred_sd.to('cpu')\n",
    "        \n",
    "        f, ax = plt.subplots(3, 3, figsize=(15, 15), sharex=True, sharey=True)\n",
    "        ax[0, 0].imshow(pred_sd.squeeze(), cmap='Blues', vmin=0, vmax=0.4, interpolation=None)\n",
    "        ax[0, 0].set_title('Predicted Snow Depth')\n",
    "        ax[0, 1].imshow(data_dict['aso_sd'].squeeze(), cmap='Blues', vmin=0, vmax=0.4, interpolation=None)\n",
    "        ax[0, 1].set_title('ASO Lidar Snow Depth')\n",
    "        ax[0, 2].imshow(data_dict['elevation'].squeeze(), cmap='viridis', interpolation='none')\n",
    "        ax[0, 2].set_title('Copernicus DEM')\n",
    "        ax[1, 0].imshow(data_dict['fcf'].squeeze(), cmap='Greens', interpolation='none')\n",
    "        ax[1, 0].set_title('Fractional Forest Cover')\n",
    "        norm_max = np.max([data_dict['green'].max(), data_dict['red'].max(), data_dict['blue'].max()]) # there are better ways to do this\n",
    "        ax[1, 1].imshow(torch.cat((data_dict['red'].squeeze()[:, :, None]/norm_max, data_dict['green'].squeeze()[:, :, None]/norm_max, data_dict['blue'].squeeze()[:, :, None]/norm_max), 2).squeeze(), interpolation='none')\n",
    "        ax[1, 1].set_title('true color image')\n",
    "        ax[1, 2].imshow(data_dict['aso_gap_map'].squeeze() + data_dict['rtc_gap_map'].squeeze() + data_dict['s2_gap_map'].squeeze(), cmap='Purples', interpolation='none')\n",
    "        ax[1, 2].set_title('ASO and RTC Gaps')\n",
    "        ax[2, 0].imshow(data_dict['ndvi'].squeeze(), cmap='YlGn', interpolation='none')\n",
    "        ax[2, 0].set_title('NDVI')\n",
    "        ax[2, 1].imshow(data_dict['ndsi'].squeeze(), cmap='BuPu', interpolation='none')\n",
    "        ax[2, 1].set_title('NDSI')\n",
    "        ax[2, 2].imshow(data_dict['ndwi'].squeeze(), cmap='YlGnBu', interpolation='none')\n",
    "        ax[2, 2].set_title('NDWI')\n",
    "        \n",
    "        # modify plot style\n",
    "        for a in ax.flat:\n",
    "            a.set_aspect('equal')\n",
    "            a.set_xticks(np.arange(0, data_dict['aso_sd'].squeeze().shape[1], 43))\n",
    "            a.set_yticks(np.arange(0, data_dict['aso_sd'].squeeze().shape[0], 43))\n",
    "            a.grid(True, linewidth=1, alpha=0.5)\n",
    "        \n",
    "        f.tight_layout()\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6e979b-7dac-44e1-8e78-fc8f28f1ebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize prediction error\n",
    "sns.set_theme()\n",
    "num_samples = 1\n",
    "norm_dict = deep_snow.dataset.norm_dict\n",
    "\n",
    "for i, data_tuple in enumerate(val_loader):\n",
    "    if i < num_samples:\n",
    "        # read data into dictionary\n",
    "        data_dict = {name: tensor for name, tensor in zip(selected_channels, data_tuple)}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Concatenate input feature channels, make prediction\n",
    "            inputs = torch.cat([data_dict[channel] for channel in input_channels], dim=1).to('cuda')\n",
    "            pred_sd = model(inputs)  # Generate predictions using the model\n",
    "            pred_sd = pred_sd.to('cpu')\n",
    "\n",
    "            # mask nodata areas\n",
    "            pred_sd = torch.where(data_dict['aso_gap_map']+data_dict['rtc_gap_map'] + data_dict['s2_gap_map'] == 0, pred_sd, torch.zeros_like(pred_sd))\n",
    "            aso_sd = torch.where(data_dict['aso_gap_map']+data_dict['rtc_gap_map'] + data_dict['s2_gap_map'] == 0, data_dict['aso_sd'], torch.zeros_like(pred_sd))\n",
    "\n",
    "            # undo normalization\n",
    "            pred_sd = deep_snow.dataset.undo_norm(pred_sd, deep_snow.dataset.norm_dict['aso_sd']).squeeze()\n",
    "            aso_sd = deep_snow.dataset.undo_norm(aso_sd, deep_snow.dataset.norm_dict['aso_sd']).squeeze()\n",
    "            \n",
    "            # mask values above 0\n",
    "            pred_sd = torch.where(pred_sd >= 0, pred_sd, torch.zeros_like(pred_sd))\n",
    "            \n",
    "            f, ax = plt.subplots(2, 2, figsize=(10,10), sharex=True, sharey=True)\n",
    "            im0 = ax[0, 0].imshow(pred_sd, cmap='Blues', vmin=0, vmax=2, interpolation='none') \n",
    "            ax[0, 0].set_title('predicted snow depth')\n",
    "            f.colorbar(im0, shrink=0.5)\n",
    "            im1 = ax[0, 1].imshow(aso_sd, cmap='Blues', vmin=0, vmax=2, interpolation='none')\n",
    "            ax[0, 1].set_title('ASO lidar snow depth')\n",
    "            f.colorbar(im1, shrink=0.5)\n",
    "\n",
    "            im2 = ax[1, 0].imshow(aso_sd-pred_sd, cmap='RdBu', vmin=-2, vmax=2, interpolation='none') \n",
    "            ax[1, 0].set_title('ASO snow depth - predicted snow depth')\n",
    "            f.colorbar(im2, shrink=0.5)\n",
    "            norm_max = np.max([data_dict['green'].max(), data_dict['red'].max(), data_dict['blue'].max()]) # there are better ways to do this\n",
    "            im3 = ax[1, 1].imshow(torch.cat((data_dict['red'].squeeze()[:, :, None]/norm_max, data_dict['green'].squeeze()[:, :, None]/norm_max, data_dict['blue'].squeeze()[:, :, None]/norm_max), 2).squeeze(), interpolation='none')\n",
    "            ax[1, 1].set_title('true color image')\n",
    "            f.colorbar(im3, shrink=0.5)\n",
    "\n",
    "            # modify plot style\n",
    "            for a in ax.flat:\n",
    "                a.set_aspect('equal')\n",
    "                a.set_xticks(np.arange(0, data_dict['aso_sd'].squeeze().shape[1], 43))\n",
    "                a.set_yticks(np.arange(0, data_dict['aso_sd'].squeeze().shape[0], 43))\n",
    "                a.grid(True, linewidth=1, alpha=0.5)\n",
    "\n",
    "            plt.tight_layout()\n",
    "    else: \n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep-snow] *",
   "language": "python",
   "name": "conda-env-deep-snow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

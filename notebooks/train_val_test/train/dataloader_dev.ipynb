{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79d10a3-2737-4486-a088-79ae27b6ecb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f6abb9-ec9e-49ce-9c80-936575faf6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are set by finding the 0.1 and 99.9 percentile across the dataset\n",
    "norm_dict = {'aso_sd':[0, 12],\n",
    "             'snodas_sd':[0, 12],\n",
    "             'vv':[-23, 6],\n",
    "             'vh':[-28, -5],\n",
    "             'cr':[-18, 0],\n",
    "             'delta_cr':[-11, 9],\n",
    "             'AOT':[32, 375],\n",
    "             'coastal':[32, 18022],\n",
    "             'blue':[50, 16145],\n",
    "             'green':[143, 15047],\n",
    "             'red':[88, 14844],\n",
    "             'red_edge1':[173, 15137],\n",
    "             'red_edge2':[267, 14473],\n",
    "             'red_edge3':[382, 14583],\n",
    "             'nir':[295, 13842],\n",
    "             'water_vapor':[396, 17480],\n",
    "             'swir1':[115, 7985],\n",
    "             'swir2':[103, 7194],\n",
    "             'scene_class_map':[0, 15],\n",
    "             'water_vapor_product':[0, 6518],\n",
    "             'fcf':[0, 1],\n",
    "             'elevation':[-100, 9000],\n",
    "             'aspect':[0, 360],\n",
    "             'slope':[0, 90],\n",
    "             'curvature':[-4, 4],\n",
    "             'tpi':[-24, 28],\n",
    "             'tri':[0, 195],\n",
    "             'latitude':[-90, 90],\n",
    "             'longitude':[-180, 180]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67153eed-dd9f-466d-ac9a-fee4518f95c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset \n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    '''\n",
    "    class that reads data from a netCDF and returns normalized tensors \n",
    "    '''\n",
    "    def __init__(self, path_list, selected_channels, norm_dict=norm_dict, norm=True, augment=True, cache_data=True):\n",
    "        self.path_list = path_list\n",
    "        self.selected_channels = selected_channels\n",
    "        self.norm_dict = norm_dict\n",
    "        self.norm = norm\n",
    "        self.augment = augment\n",
    "        self.cache_data = cache_data\n",
    "        self.cache = [None] * len(path_list)\n",
    "        \n",
    "    #dataset length\n",
    "    def __len__(self):\n",
    "        self.filelength = len(self.path_list)\n",
    "        return self.filelength\n",
    "    \n",
    "    def get_standard_input(ds, input_name, alt_name=None, return_numpy=False):\n",
    "        if alt_name == None:\n",
    "            input_arr = torch.from_numpy(np.float32(ds[input_name].values))\n",
    "        else:\n",
    "            input_arr = torch.from_numpy(np.float32(ds[alt_name].values))\n",
    "        \n",
    "        if return_numpy == True:\n",
    "            return input_arr\n",
    "        else:\n",
    "            if self.norm == True:\n",
    "                input_arr = torch.clamp(calc_norm(input_arr, self.norm_dict[input_name]), 0, 1)\n",
    "                return input_arr[None, :, :]\n",
    "            else:\n",
    "                return input_arr[None, :, :]\n",
    "\n",
    "    def get_S1_rtc(ds, snow_status, polarization, mean=False, return_numpy==False):\n",
    "        if mean == True:\n",
    "            S1_rtc = torch.from_numpy(db_scale(np.float32(ds[f'{snow_status}_{polarization}_{mean}'].values)))\n",
    "        else:\n",
    "            S1_rtc = torch.from_numpy(db_scale(np.float32(ds[f'{snow_status}_{polarization}'].values)))\n",
    "        if return_numpy == True:\n",
    "            return S1_rtc\n",
    "        else:\n",
    "            if self.norm == True:\n",
    "                S1_rtc = torch.clamp(calc_norm(S1_rtc, self.norm_dict[polarization]), 0, 1)\n",
    "                return S1_rtc[None, :, :]\n",
    "            else:\n",
    "                return S1_rtc[None, :, :]\n",
    "\n",
    "    def get_band_index(ds, index_name, return_numpy==False):\n",
    "        if index_name == 'ndvi':\n",
    "            nir = get_standard_input(ds, 'nir', 'B08', return_numpy=True)\n",
    "            red = get_standard_input(ds, 'red', 'B04', return_numpy=True)\n",
    "            index_arr = torch.nan_to_num((nir - red)/(nir + red), 0)\n",
    "        elif index_name == 'ndsi':\n",
    "            green = get_standard_input(ds, 'green', 'B03', return_numpy=True)\n",
    "            swir1 = get_standard_input(ds, 'swir1', 'B11', return_numpy=True)\n",
    "            index_arr = torch.nan_to_num((green - swir1)/(green + swir1), 0)\n",
    "        elif index_name == 'ndwi':\n",
    "            green = get_standard_input(ds, 'green', 'B03', return_numpy=True)\n",
    "            nir = get_standard_input(ds, 'nir', 'B08', return_numpy=True)\n",
    "            index_arr = torch.nan_to_num((green - nir)/(green + nir), 0)\n",
    "        if return_numpy == True:\n",
    "            return index_arr\n",
    "        else:\n",
    "            if self.norm == True:\n",
    "                index_arr = torch.clamp(calc_norm(index_arr, [-1, 1]), 0, 1)\n",
    "                return index_arr[None, :, :]\n",
    "            else:\n",
    "                return index_arr[None, :, :]\n",
    "\n",
    "    def get_s1_cross_ratio(ds, snow_status, mean=False, return_numpy=False):\n",
    "        S1_rtc_vv = get_S1_rtc(ds, snow_status, 'vv', mean, return_numpy=True)\n",
    "        S1_rtc_vh = get_S1_rtc(ds, snow_status, 'vh', mean, return_numpy=True)\n",
    "        S1_rtc_cr = S1_rtc_vh - S1_rtc_vv\n",
    "        if return_numpy == True:\n",
    "            return S1_rtc_cr\n",
    "        else:\n",
    "            if self.norm == True:\n",
    "                S1_rtc_cr = torch.clamp(calc_norm(S1_rtc_cr, self.norm_dict['cr']), 0, 1)\n",
    "                return S1_rtc_cr[None, :, :]\n",
    "            else:\n",
    "                return S1_rtc_cr[None, :, :]\n",
    "\n",
    "    def get_s1_delta_cross_ratio(ds, mean=False, return_numpy=False):\n",
    "        S1_rtc_snowon_cr = get_s1_cross_ratio(ds, 'snowon', mean, return_numpy=True)\n",
    "        S1_rtc_snowoff_cr = get_s1_cross_ratio(ds, 'snowoff', mean, return_numpy=True)\n",
    "        S1_rtc_delta_cr = S1_rtc_snowon_cr - S1_rtc_snowoff_cr\n",
    "        if return_numpy == True:\n",
    "            return S1_rtc_delta_cr\n",
    "        else:\n",
    "            if self.norm == True:\n",
    "                S1_rtc_delta_cr = torch.clamp(calc_norm(S1_rtc_delta_cr, self.norm_dict['delta_cr']), 0, 1)\n",
    "                return S1_rtc_delta_cr[None, :, :]\n",
    "            else:\n",
    "                return S1_rtc_delta_cr[None, :, :]\n",
    "\n",
    "    def get_directionality(ds, directionality_name, return_numpy=False):\n",
    "        aspect = get_standard_input(ds, 'aspect', return_numpy=True)\n",
    "        aspect_rad = np.deg2rad(aspect)\n",
    "        if directionality_name == 'northness':\n",
    "            directionality_arr = np.cos(aspect_rad)\n",
    "        elif directionality_name == 'eastness':\n",
    "            directionality_arr = np.sin(aspect_rad)\n",
    "        if return_numpy == True:\n",
    "            return directionality_arr\n",
    "        else:\n",
    "            if self.norm == True:\n",
    "                directionality_arr = torch.clamp(calc_norm(directionality_arr, [-1, 1]), 0, 1)\n",
    "                return directionality_arr[None, :, :]\n",
    "            else:\n",
    "                return directionality_arr[None, :, :]\n",
    "\n",
    "    def get_dowy(ds, idx, return_numpy=False):\n",
    "        get_standard_input(ds, 'aso_sd', return_numpy=True)\n",
    "        fn = os.path.split(self.path_list[idx])[-1]\n",
    "        dowy_1d = calc_dowy(pd.to_datetime(fn.split('_')[4]).dayofyear)\n",
    "        dowy = torch.full_like(aso_sd, dowy_1d)\n",
    "        if return_numpy == True:\n",
    "            return dowy\n",
    "        else:\n",
    "            if self.norm == True:\n",
    "                dowy = torch.clamp(calc_norm(dowy, [0, 365]), 0, 1)\n",
    "                return dowy[None, :, :]\n",
    "            else:\n",
    "                return dowy[None, :, :]\n",
    "        \n",
    "    #load images\n",
    "    def __getitem__(self,idx):\n",
    "        if self.cache_data and self.cache[idx] is not None:\n",
    "            selected_data = self.cache[idx]\n",
    "        else:\n",
    "            ds = xr.open_dataset(self.path_list[idx])\n",
    "            \n",
    "            # Store final selected data here\n",
    "            selected_data = []\n",
    "\n",
    "            for channel in self.selected_channels:\n",
    "                if channel == 'aso_sd':\n",
    "                    selected_data.append(get_standard_input(ds, 'aso_sd')\n",
    "                elif channel == 'snowon_vv':\n",
    "                    selected_data.append(get_S1_rtc(ds, 'snowon', 'vv')\n",
    "                elif channel == 'snowon_vh':\n",
    "                    selected_data.append(get_S1_rtc(ds, 'snowon', 'vh')\n",
    "                elif channel == 'snowoff_vv':\n",
    "                    selected_data.append(get_S1_rtc(ds, 'snowoff', 'vv')\n",
    "                elif channel == 'snowoff_vh':\n",
    "                    selected_data.append(get_S1_rtc(ds, 'snowoff', 'vh')\n",
    "                elif channel == 'snowon_vv_mean':\n",
    "                    selected_data.append(get_S1_rtc(ds, 'snowon', 'vv', mean=True)\n",
    "                elif channel == 'snowon_vh_mean':\n",
    "                    selected_data.append(get_S1_rtc(ds, 'snowon', 'vh', mean=True)\n",
    "                elif channel == 'snowoff_vv_mean':\n",
    "                    selected_data.append(get_S1_rtc(ds, 'snowoff', 'vv', mean=True)\n",
    "                elif channel == 'snowoff_vh_mean':\n",
    "                    selected_data.append(get_S1_rtc(ds, 'snowoff', 'vh', mean=True)\n",
    "                elif channel == 'aerosol_optical_thickness':\n",
    "                    selected_data.append(get_standard_input(ds, 'aerosol_optical_thickness', 'AOT')\n",
    "                elif channel == 'coastal_aerosol':\n",
    "                    selected_data.append(get_standard_input(ds, 'coastal_aerosol', 'B01')\n",
    "                elif channel == 'blue':\n",
    "                    selected_data.append(get_standard_input(ds, 'blue', 'B02')\n",
    "                elif channel == 'green':\n",
    "                    selected_data.append(get_standard_input(ds, 'green', 'B03')\n",
    "                elif channel == 'red':\n",
    "                    selected_data.append(get_standard_input(ds, 'red', 'B04')\n",
    "                elif channel == 'red_edge1':\n",
    "                    selected_data.append(get_standard_input(ds, 'red_edge1', 'B05')\n",
    "                elif channel == 'red_edge2':\n",
    "                    selected_data.append(get_standard_input(ds, 'red_edge2', 'B06')\n",
    "                elif channel == 'red_edge3':\n",
    "                    selected_data.append(get_standard_input(ds, 'red_edge3', 'B07')\n",
    "                elif channel == 'nir':\n",
    "                    selected_data.append(get_standard_input(ds, 'nir', 'B08')\n",
    "                elif channel == 'water_vapor':\n",
    "                    selected_data.append(get_standard_input(ds, 'water_vapor', 'B09')\n",
    "                elif channel == 'swir1':\n",
    "                    selected_data.append(get_standard_input(ds, 'swir1', 'B10')\n",
    "                elif channel == 'swir2':\n",
    "                    selected_data.append(get_standard_input(ds, 'swir2', 'B11')\n",
    "                elif channel == 'scene_class_map':\n",
    "                    selected_data.append(get_standard_input(ds, 'scene_class_map', 'SCL')\n",
    "                elif channel == 'water_vapor_product':\n",
    "                    selected_data.append(get_standard_input(ds, 'water_vapor_product', 'WVP')\n",
    "                elif channel == 'snodas_sd':\n",
    "                    selected_data.append(get_standard_input(ds, 'snodas_sd')\n",
    "                elif channel == 'fcf':\n",
    "                    selected_data.append(get_standard_input(ds, 'fcf')\n",
    "                elif channel == 'elevation':\n",
    "                    selected_data.append(get_standard_input(ds, 'elevation')\n",
    "                elif channel == 'slope':\n",
    "                    selected_data.append(get_standard_input(ds, 'slope')\n",
    "                elif channel == 'aspect':\n",
    "                    selected_data.append(get_standard_input(ds, 'aspect')\n",
    "                elif channel == 'northness':\n",
    "                    selected_data.append(get_directionality(ds, 'northness')\n",
    "                elif channel == 'eastness':\n",
    "                    selected_data.append(get_directionality(ds, 'eastness')\n",
    "                elif channel == 'curvature':\n",
    "                    selected_data.append(get_standard_input(ds, 'curvature')\n",
    "                elif channel == 'tpi':\n",
    "                    selected_data.append(get_standard_input(ds, 'tpi')\n",
    "                elif channel == 'tri':\n",
    "                    selected_data.append(get_standard_input(ds, 'tri')\n",
    "                elif channel == 'latitude':\n",
    "                    selected_data.append(get_standard_input(ds, 'latitude')\n",
    "                elif channel == 'longitude':\n",
    "                    selected_data.append(get_standard_input(ds, 'longitude')\n",
    "                elif channel == 'dowy':\n",
    "                    selected_data.append(get_dowy(ds, idx)\n",
    "                elif channel == 'ndvi': \n",
    "                    selected_data.append(get_band_index(ds, 'ndvi')\n",
    "                elif channel == 'ndsi':\n",
    "                    selected_data.append(get_band_index(ds, 'ndsi')\n",
    "                elif channel == 'ndwi':\n",
    "                    selected_data.append(get_band_index(ds, 'ndwi')\n",
    "                elif channel == 'snowon_cr': \n",
    "                    selected_data.append(get_s1_cross_ratio(ds, 'snowon')\n",
    "                elif channel == 'snowoff_cr':\n",
    "                    selected_data.append(get_s1_cross_ratio(ds, 'snowoff')\n",
    "                elif channel == 'delta_cr':\n",
    "                    selected_data.append(get_s1_delta_cross_ratio(ds)\n",
    "                elif channel == 'aso_gap_map':\n",
    "                    selected_data.append(torch.from_numpy(np.float32(ds.aso_gap_map.values))[None, :, :])\n",
    "                elif channel == 'rtc_gap_map':\n",
    "                    selected_data.append(torch.from_numpy(np.float32(ds.rtc_gap_map.values))[None, :, :])\n",
    "                elif channel == 'rtc_mean_gap_map':\n",
    "                    selected_data.append(torch.from_numpy(np.float32(ds.rtc_mean_gap_map.values))[None, :, :])\n",
    "                elif channel == 's2_gap_map':\n",
    "                    selected_data.append(torch.from_numpy(np.float32(ds.s2_gap_map.values))[None, :, :])\n",
    "\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown channel: {channel}\")\n",
    "\n",
    "            # Cache the result\n",
    "            if self.cache_data:\n",
    "                self.cache[idx] = selected_data\n",
    "    \n",
    "        # Apply augmentation\n",
    "        if self.augment:\n",
    "            randoms = [random.random(), random.random(), random.randint(0, 3)]\n",
    "            selected_data = [random_transform(img, randoms) for img in selected_data]\n",
    "    \n",
    "        return tuple(selected_data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb513be9-573e-4946-b50e-da124f124b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset \n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    '''\n",
    "    class that reads data from a netCDF and returns normalized tensors \n",
    "    '''\n",
    "    def __init__(self, path_list, selected_channels, norm_dict=norm_dict, norm=True, augment=True, cache_data=True):\n",
    "        self.path_list = path_list\n",
    "        self.selected_channels = selected_channels\n",
    "        self.norm_dict = norm_dict\n",
    "        self.norm = norm\n",
    "        self.augment = augment\n",
    "        self.cache_data = cache_data\n",
    "        self.cache = [None] * len(path_list)\n",
    "        \n",
    "    #dataset length\n",
    "    def __len__(self):\n",
    "        self.filelength = len(self.path_list)\n",
    "        return self.filelength\n",
    "    \n",
    "    #load images\n",
    "    def __getitem__(self,idx):\n",
    "        if self.cache_data and self.cache[idx] is not None:\n",
    "            selected_data = self.cache[idx]\n",
    "        else:\n",
    "            ds = xr.open_dataset(self.path_list[idx])\n",
    "            # to downsample dataset\n",
    "            #ds = ds.coarsen(x = 6, boundary = 'trim').mean().coarsen(y = 6, boundary = 'trim').mean()\n",
    "            \n",
    "            # convert to tensors\n",
    "            snowon_vv_mean = torch.from_numpy(db_scale(np.float32(ds.snowon_vv_mean.values)))\n",
    "            snowon_vh_mean = torch.from_numpy(db_scale(np.float32(ds.snowon_vh_mean.values)))\n",
    "            snowoff_vv_mean = torch.from_numpy(db_scale(np.float32(ds.snowoff_vv_mean.values)))\n",
    "            snowoff_vh_mean = torch.from_numpy(db_scale(np.float32(ds.snowoff_vh_mean.values)))\n",
    "            aerosol_optical_thickness = torch.from_numpy(np.float32(ds.AOT.values))\n",
    "            coastal_aerosol = torch.from_numpy(np.float32(ds.B01.values))\n",
    "            blue = torch.from_numpy(np.float32(ds.B02.values))\n",
    "            green = torch.from_numpy(np.float32(ds.B03.values))\n",
    "            red = torch.from_numpy(np.float32(ds.B04.values))\n",
    "            red_edge1 = torch.from_numpy(np.float32(ds.B05.values))\n",
    "            red_edge2 = torch.from_numpy(np.float32(ds.B06.values))\n",
    "            red_edge3 = torch.from_numpy(np.float32(ds.B07.values))\n",
    "            nir = torch.from_numpy(np.float32(ds.B08.values))\n",
    "            water_vapor = torch.from_numpy(np.float32(ds.B09.values))\n",
    "            swir1 = torch.from_numpy(np.float32(ds.B11.values))\n",
    "            swir2 = torch.from_numpy(np.float32(ds.B12.values))\n",
    "            scene_class_map = torch.from_numpy(np.float32(ds.SCL.values))\n",
    "            water_vapor_product = torch.from_numpy(np.float32(ds.WVP.values))\n",
    "            snodas_sd = torch.from_numpy(np.float32(ds.snodas_sd.values))\n",
    "            fcf = torch.from_numpy(np.float32(ds.fcf.values))\n",
    "            elevation = torch.from_numpy(np.float32(ds.elevation.values))\n",
    "            slope = torch.from_numpy(np.float32(ds.slope.values))\n",
    "            aspect = torch.from_numpy(np.float32(ds.aspect.values))\n",
    "            curvature = torch.from_numpy(np.float32(ds.curvature.values))\n",
    "            tri = torch.from_numpy(np.float32(ds.tri.values))\n",
    "            tpi = torch.from_numpy(np.float32(ds.tpi.values))\n",
    "            latitude = torch.from_numpy(np.float32(ds.latitude.values))\n",
    "            longitude = torch.from_numpy(np.float32(ds.longitude.values))\n",
    "            aso_gap_map = torch.from_numpy(np.float32(ds.aso_gap_map.values))\n",
    "            rtc_gap_map = torch.from_numpy(np.float32(ds.rtc_gap_map.values))\n",
    "            rtc_mean_gap_map = torch.from_numpy(np.float32(ds.rtc_mean_gap_map.values))\n",
    "            s2_gap_map = torch.from_numpy(np.float32(ds.s2_gap_map.values))\n",
    "    \n",
    "            # calculate some other inputs for our CNN\n",
    "            ndvi = torch.nan_to_num((nir - red)/(nir + red), 0)\n",
    "            ndsi = torch.nan_to_num((green - swir1)/(green + swir1), 0)\n",
    "            ndwi = torch.nan_to_num((green - nir)/(green + nir), 0)\n",
    "\n",
    "            # calculate S1 polarization cross ratios\n",
    "            snowon_cr = snowon_vh - snowon_vv\n",
    "            snowoff_cr = snowoff_vh - snowoff_vv\n",
    "            delta_cr = snowon_cr - snowoff_cr\n",
    "\n",
    "            # calculate northness and eastness\n",
    "            aspect_rad = np.deg2rad(aspect)\n",
    "            northness = np.cos(aspect_rad)\n",
    "            eastness = np.sin(aspect_rad)\n",
    "    \n",
    "            fn = os.path.split(self.path_list[idx])[-1]\n",
    "            dowy_1d = calc_dowy(pd.to_datetime(fn.split('_')[4]).dayofyear)\n",
    "            dowy = torch.full_like(aso_sd, dowy_1d)\n",
    "                \n",
    "            # normalize layers (except gap maps and fcf)\n",
    "            if self.norm == True:\n",
    "                \n",
    "                snodas_sd = torch.clamp(calc_norm(snodas_sd, self.norm_dict['aso_sd']), 0, 1)\n",
    "                \n",
    "                snowon_vh = torch.clamp(calc_norm(snowon_vh, self.norm_dict['vh']), 0, 1)\n",
    "                snowoff_vv = torch.clamp(calc_norm(snowoff_vv, self.norm_dict['vv']), 0, 1)\n",
    "                snowoff_vh = torch.clamp(calc_norm(snowoff_vh, self.norm_dict['vh']), 0, 1)\n",
    "                snowon_vv_mean = torch.clamp(calc_norm(snowon_vv_mean, self.norm_dict['vv']), 0, 1)\n",
    "                snowon_vh_mean = torch.clamp(calc_norm(snowon_vh_mean, self.norm_dict['vh']), 0, 1)\n",
    "                snowoff_vv_mean = torch.clamp(calc_norm(snowoff_vv_mean, self.norm_dict['vv']), 0, 1)\n",
    "                snowoff_vh_mean = torch.clamp(calc_norm(snowoff_vh_mean, self.norm_dict['vh']), 0, 1)\n",
    "                aerosol_optical_thickness = torch.clamp(calc_norm(aerosol_optical_thickness, self.norm_dict['AOT']), 0, 1)\n",
    "                coastal_aerosol = torch.clamp(calc_norm(coastal_aerosol, self.norm_dict['coastal']), 0, 1)\n",
    "                blue = torch.clamp(calc_norm(blue, self.norm_dict['blue']), 0, 1)\n",
    "                green = torch.clamp(calc_norm(green, self.norm_dict['green']), 0, 1)\n",
    "                red = torch.clamp(calc_norm(red, self.norm_dict['red']), 0, 1)\n",
    "                red_edge1 = torch.clamp(calc_norm(red_edge1, self.norm_dict['red_edge1']), 0, 1)\n",
    "                red_edge2 = torch.clamp(calc_norm(red_edge2, self.norm_dict['red_edge2']), 0, 1)\n",
    "                red_edge3 = torch.clamp(calc_norm(red_edge3, self.norm_dict['red_edge3']), 0, 1)\n",
    "                nir = torch.clamp(calc_norm(nir, self.norm_dict['nir']), 0, 1)\n",
    "                water_vapor = torch.clamp(calc_norm(water_vapor, self.norm_dict['water_vapor']), 0, 1)\n",
    "                swir1 = torch.clamp(calc_norm(swir1, self.norm_dict['swir1']), 0, 1)\n",
    "                swir2 = torch.clamp(calc_norm(swir2, self.norm_dict['swir2']), 0, 1)\n",
    "                scene_class_map = torch.clamp(calc_norm(scene_class_map, self.norm_dict['scene_class_map']), 0, 1)\n",
    "                water_vapor_product = torch.clamp(calc_norm(water_vapor_product, self.norm_dict['water_vapor_product']), 0, 1)\n",
    "                elevation = torch.clamp(calc_norm(elevation, self.norm_dict['elevation']), 0, 1)\n",
    "                aspect = torch.clamp(calc_norm(aspect, self.norm_dict['aspect']), 0, 1)\n",
    "                northness = torch.clamp(calc_norm(northness, [-1, 1]), 0, 1)\n",
    "                eastness = torch.clamp(calc_norm(eastness, [-1, 1]), 0, 1)\n",
    "                slope = torch.clamp(calc_norm(slope, self.norm_dict['slope']), 0, 1)\n",
    "                curvature = torch.clamp(calc_norm(curvature, self.norm_dict['curvature']), 0, 1)\n",
    "                tpi = torch.clamp(calc_norm(tpi, self.norm_dict['tpi']), 0, 1)\n",
    "                tri = torch.clamp(calc_norm(tri, self.norm_dict['tri']), 0, 1)\n",
    "                latitude = torch.clamp(calc_norm(latitude, self.norm_dict['latitude']), 0, 1)\n",
    "                longitude = torch.clamp(calc_norm(longitude, self.norm_dict['longitude']), 0, 1)\n",
    "                dowy = torch.clamp(torch.nan_to_num(calc_norm(dowy, [0, 365]), 0), 0, 1)\n",
    "                ndvi = torch.clamp(torch.nan_to_num(calc_norm(ndvi, [-1, 1]), 0), 0, 1)\n",
    "                ndsi = torch.clamp(torch.nan_to_num(calc_norm(ndsi, [-1, 1]), 0), 0, 1)\n",
    "                ndwi = torch.clamp(torch.nan_to_num(calc_norm(ndwi, [-1, 1]), 0), 0, 1)\n",
    "                snowon_cr = torch.clamp(torch.nan_to_num(calc_norm(snowon_cr, self.norm_dict['cr']), 0), 0, 1)\n",
    "                snowoff_cr = torch.clamp(torch.nan_to_num(calc_norm(snowoff_cr, self.norm_dict['cr']), 0), 0, 1)\n",
    "                delta_cr = torch.clamp(torch.nan_to_num(calc_norm(delta_cr, self.norm_dict['delta_cr']), 0), 0, 1)\n",
    "    \n",
    "            data_dict = {'aso_sd':aso_sd[None, :, :],\n",
    "                        'snowon_vv': snowon_vv[None, :, :],\n",
    "                        'snowon_vh': snowon_vh[None, :, :],\n",
    "                        'snowoff_vv': snowoff_vv[None, :, :],\n",
    "                        'snowoff_vh': snowoff_vh[None, :, :],\n",
    "                        'snowon_vv_mean': snowon_vv_mean[None, :, :],\n",
    "                        'snowon_vh_mean': snowon_vh_mean[None, :, :],\n",
    "                        'snowoff_vv_mean': snowoff_vv_mean[None, :, :],\n",
    "                        'snowoff_vh_mean': snowoff_vh_mean[None, :, :],\n",
    "                        'aerosol_optical_thickness': aerosol_optical_thickness[None, :, :],\n",
    "                        'coastal_aerosol':coastal_aerosol[None, :, :],\n",
    "                        'blue': blue[None, :, :],\n",
    "                        'green': green[None, :, :],\n",
    "                        'red': red[None, :, :],\n",
    "                        'red_edge1': red_edge1[None, :, :],\n",
    "                        'red_edge2': red_edge2[None, :, :],\n",
    "                        'red_edge3': red_edge3[None, :, :],\n",
    "                        'nir': nir[None, :, :],\n",
    "                        'water_vapor': water_vapor[None, :, :],\n",
    "                        'swir1': swir1[None, :, :],\n",
    "                        'swir2': swir2[None, :, :],\n",
    "                        'scene_class_map': scene_class_map[None, :, :],\n",
    "                        'water_vapor_product': water_vapor_product[None, :, :],\n",
    "                        'snodas_sd': snodas_sd[None, :, :],\n",
    "                        'fcf': fcf[None, :, :],\n",
    "                        'elevation': elevation[None, :, :],\n",
    "                        'slope': slope[None, :, :],\n",
    "                        'aspect': aspect[None, :, :],\n",
    "                        'northness': northness[None, :, :],\n",
    "                        'eastness': eastness[None, :, :],\n",
    "                        'curvature': curvature[None, :, :],\n",
    "                        'tpi': tpi[None, :, :],\n",
    "                        'tri': tri[None, :, :],\n",
    "                        'latitude': latitude[None, :, :],\n",
    "                        'longitude': longitude[None, :, :],\n",
    "                        'dowy': dowy[None, :, :],\n",
    "                        'ndvi': ndvi[None, :, :],\n",
    "                        'ndsi': ndsi[None, :, :],\n",
    "                        'ndwi': ndwi[None, :, :],\n",
    "                        'snowon_cr': snowon_cr[None, :, :],\n",
    "                        'snowoff_cr': snowoff_cr[None, :, :],\n",
    "                        'delta_cr': delta_cr[None, :, :],\n",
    "                        'aso_gap_map': aso_gap_map[None, :, :],\n",
    "                        'rtc_gap_map': rtc_gap_map[None, :, :],\n",
    "                        'rtc_mean_gap_map': rtc_mean_gap_map[None, :, :],\n",
    "                        's2_gap_map': s2_gap_map[None, :, :]}\n",
    "    \n",
    "            # Select only the specified channels\n",
    "            selected_data = [data_dict[channel] for channel in self.selected_channels]\n",
    "\n",
    "            # store data in memory to speed up training\n",
    "            if self.cache_data == True:\n",
    "                self.cache[idx] = selected_data\n",
    "\n",
    "        if self.cache_data == True:\n",
    "            selected_data = self.cache[idx]\n",
    "        \n",
    "        # Apply transformations to each selected channel\n",
    "        if self.augment:\n",
    "            randoms = [random.random(), random.random(), random.randint(0, 3)]\n",
    "            selected_data = [random_transform(img, randoms) for img in selected_data]\n",
    "        \n",
    "        return tuple(selected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb9bc6d-fa9c-418c-94a9-5b8ed4650188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __getitem__(self, idx):\n",
    "    if self.cache_data and self.cache[idx] is not None:\n",
    "        selected_data = self.cache[idx]\n",
    "    else:\n",
    "        ds = xr.open_dataset(self.path_list[idx])\n",
    "        fn = os.path.split(self.path_list[idx])[-1]\n",
    "        dowy_1d = calc_dowy(pd.to_datetime(fn.split('_')[4]).dayofyear)\n",
    "        \n",
    "        # Store final selected data here\n",
    "        selected_data = []\n",
    "\n",
    "        # Precompute shared intermediates if needed\n",
    "        nir = red = green = swir1 = aspect = None  # avoid recomputation\n",
    "\n",
    "        for channel in self.selected_channels:\n",
    "            if channel == 'aso_sd':\n",
    "                arr = torch.from_numpy(np.float32(ds.aso_sd.values))\n",
    "                if self.norm:\n",
    "                    arr = torch.clamp(calc_norm(arr, self.norm_dict['aso_sd']), 0, 1)\n",
    "                selected_data.append(arr[None, :, :])\n",
    "\n",
    "            elif channel == 'snowon_vv':\n",
    "                arr = torch.from_numpy(db_scale(np.float32(ds.snowon_vv.values)))\n",
    "                if self.norm:\n",
    "                    arr = torch.clamp(calc_norm(arr, self.norm_dict['vv']), 0, 1)\n",
    "                selected_data.append(arr[None, :, :])\n",
    "\n",
    "            # [Repeat for all simple channels like snowon_vh, swir2, etc.]\n",
    "\n",
    "            elif channel == 'ndvi':\n",
    "                if nir is None:\n",
    "                    nir = torch.from_numpy(np.float32(ds.B08.values))\n",
    "                    if self.norm:\n",
    "                        nir = torch.clamp(calc_norm(nir, self.norm_dict['nir']), 0, 1)\n",
    "                if red is None:\n",
    "                    red = torch.from_numpy(np.float32(ds.B04.values))\n",
    "                    if self.norm:\n",
    "                        red = torch.clamp(calc_norm(red, self.norm_dict['red']), 0, 1)\n",
    "                ndvi = torch.nan_to_num((nir - red) / (nir + red), 0)\n",
    "                ndvi = torch.clamp(calc_norm(ndvi, [-1, 1]), 0, 1) if self.norm else ndvi\n",
    "                selected_data.append(ndvi[None, :, :])\n",
    "\n",
    "            elif channel == 'northness':\n",
    "                if aspect is None:\n",
    "                    aspect = torch.from_numpy(np.float32(ds.aspect.values))\n",
    "                northness = torch.cos(np.deg2rad(aspect))\n",
    "                if self.norm:\n",
    "                    northness = torch.clamp(calc_norm(northness, [-1, 1]), 0, 1)\n",
    "                selected_data.append(northness[None, :, :])\n",
    "\n",
    "            elif channel == 'dowy':\n",
    "                shape = ds.aso_sd.shape if 'aso_sd' in ds else ds[list(ds.data_vars)[0]].shape\n",
    "                arr = torch.full(shape, dowy_1d, dtype=torch.float32)\n",
    "                if self.norm:\n",
    "                    arr = torch.clamp(torch.nan_to_num(calc_norm(arr, [0, 365]), 0), 0, 1)\n",
    "                selected_data.append(arr[None, :, :])\n",
    "\n",
    "            # Handle others similarly...\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown channel: {channel}\")\n",
    "\n",
    "        # Cache the result\n",
    "        if self.cache_data:\n",
    "            self.cache[idx] = selected_data\n",
    "\n",
    "    # Apply augmentation\n",
    "    if self.augment:\n",
    "        randoms = [random.random(), random.random(), random.randint(0, 3)]\n",
    "        selected_data = [random_transform(img, randoms) for img in selected_data]\n",
    "\n",
    "    return tuple(selected_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep-snow] *",
   "language": "python",
   "name": "conda-env-deep-snow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
